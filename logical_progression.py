# -*- coding: utf-8 -*-
"""logical progression.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Zg5Wu15PWiaa0fB3uSrWS3Q7HwdrglBU
"""

from google.colab import files
uploaded = files.upload()

import pandas as pd
import numpy as np

df = pd.read_csv('amazon_reviews.csv')
#df = pd.read_csv('Amazon_Reviews.csv', engine='python', on_bad_lines='skip')

df.head(20)
print(df.shape)
print(df)
df.columns

df.info()
df.isnull().sum()

df = df[['reviewText', 'overall']]   # keep only needed columns
df = df.dropna()

def label_sentiment(r):
    if r >= 4:
        return "positive"
    elif r <= 2:
        return "negative"
    else:
        return "neutral"

df["sentiment"] = df["overall"].apply(label_sentiment)
df = df[df.sentiment != "neutral"]  # optional
df

!pip install nltk

import re  #regular expression
import nltk
nltk.download('stopwords') #no meaning words remover
from nltk.corpus import stopwords
from nltk.stem.porter import PorterStemmer

"""corpus=[]
for i in range (0,2000):
    stop_words = set(stopwords.words("english"))
    text = text.lower()
    text = re.sub(r'http\S+', '', text)  # remove links
    text = re.sub(r'[^a-zA-Z ]', '', text)  # remove punctuation/numbers
    text = text.split()
    text = [word for word in text if word not in stop_words]"""


stop_words = set(stopwords.words("english"))

def clean_text(text):
    text = str(text)
    text = text.lower()
    text = re.sub(r'http\S+', '', text)  # remove links
    text = re.sub(r'[^a-zA-Z ]', '', text)  # remove punctuation/numbers
    text = text.split()
    text = [word for word in text if word not in stop_words]  # remove stopwords

    ps= PorterStemmer()
    text=[ps.stem(word) for word in text]

    text = " ".join(text)

    return text

#df['reviewText'] = df['reviewText'].fillna("")
df["cleaned_review"] = df["reviewText"].apply(clean_text)
df.head()

print(df.columns
      )

y_train.value_counts()

from sklearn.model_selection import train_test_split

X = df["cleaned_review"]
y = df["sentiment"]

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.4
)

from sklearn.feature_extraction.text import TfidfVectorizer

tfidf = TfidfVectorizer(max_features=5000)
X_train_tfidf = tfidf.fit_transform(X_train)
X_test_tfidf = tfidf.transform(X_test)

#maintaining imbalance
from imblearn.over_sampling import RandomOverSampler

ros = RandomOverSampler(random_state=42)
X_resampled, y_resampled = ros.fit_resample(X_train_tfidf, y_train)
y_resampled.value_counts()

"""print(X_train_tfidf)
"""
print(X_test_tfidf)

from sklearn.linear_model import LogisticRegression

model = LogisticRegression(max_iter=1000)
model.fit(X_resampled, y_resampled)

from sklearn.metrics import accuracy_score, classification_report


pred = model.predict(X_test_tfidf)
print("Accuracy:", accuracy_score(y_test, pred))
print(classification_report(y_test, pred))

"""lr = LogisticRegression()
lr.fit(X_train_tfidf, y_train)
pred_lr = lr.predict(X_test_tfidf)

print("\nLogistic Regression Results:")
print(classification_report(y_test, pred_lr))

from sklearn.ensemble import RandomForestClassifier

rf = RandomForestClassifier()
rf.fit(X_train_tfidf, y_train)
pred_rf = rf.predict(X_test_tfidf)

print("\nRandom Forest Results:")
print(classification_report(y_test, pred_rf))

from sklearn.naive_bayes import MultinomialNB
nb = MultinomialNB()
nb.fit(X_train_tfidf, y_train)
pred_nb = nb.predict(X_test_tfidf)

print("\nNaive Bayes Results:")
print(classification_report(y_test, pred_nb))
"""

"""new_review = "worst."

# Clean
cleaned = clean_text(new_review[0])

# Vectorize using SAME tfidf
vectorized = tfidf.transform([cleaned])

# Predict
prediction = model.predict(vectorized)

print("Sentiment:", prediction[0])

"""
new_reviews = [
    "Worst item I ever bought!",
    "Very good quality, highly recommended.",
    "Not worth the price.",
    "Absolutely fantastic!"
]

cleaned = [clean_text(r) for r in new_reviews]
vectors = tfidf.transform(cleaned)
predictions = model.predict(vectors)

for r, p in zip(new_reviews, predictions):
    print(r, "--->", p)

"""reviews = [
    "Worst item I ever bought!",
    "Very good quality, highly recommended.",
    "Not worth the price.",
    "Absolutely fantastic!"
]

cleaned_reviews = [clean_text(r) for r in reviews]

# Use SAME tfidf vectorizer
vec = tfidf.transform(cleaned_reviews)

preds = model.predict(vec)

for r, p in zip(reviews, preds):
    print(r, " --> ", p)

test_reviews = [
    "The product is amazing!",
    "Worst purchase ever."
]

test_labels = ["positive", "negative"]

cleaned = [clean_text(r) for r in test_reviews]
vec = tfidf.transform(cleaned)

preds = model.predict(vec)

from sklearn.metrics import accuracy_score

print("Accuracy:", accuracy_score(test_labels, preds))

for r, p in zip(reviews, preds):
    print(r, " --> ", p)
"""